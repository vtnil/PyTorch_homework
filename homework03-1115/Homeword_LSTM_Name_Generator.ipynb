{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "# 尝试使用gpu加速\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Polish', 'Chinese', 'Spanish', 'French', 'Irish', 'Scottish', 'Italian', 'Portuguese', 'Korean', 'German', 'Arabic', 'Vietnamese', 'English', 'Czech', 'Japanese', 'Greek', 'Dutch', 'Russian']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Italian', 'Carbone')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, [48, 8, 11, 18, 14, 13], [8, 11, 18, 14, 13, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        self.category_embedding = nn.Embedding(category_size, hidden_size)\n",
    "        self.name_embedding = nn.Embedding(name_size, hidden_size)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm = nn.LSTM(hidden_size * 2, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "        category_embedded = self.category_embedding(category_variable)\n",
    "        name_embedded = self.name_embedding(name_variable)\n",
    "        embedded = torch.cat((category_embedded, name_embedded), 1)\n",
    "        embedded = embedded.view(1, 1, embedded.size(1))\n",
    "#         print(embedded);\n",
    "        \n",
    "        # 从输入到隐含层的计算\n",
    "        output, hidden = self.lstm(embedded, hidden); \n",
    "        \n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output = output[:,-1,...];\n",
    "        \n",
    "        \n",
    "\n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "        \n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        \n",
    "\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).type(dtype)\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).type(dtype)\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    lstm.train()\n",
    "    \n",
    "    loss = Variable(torch.FloatTensor([0])).type(dtype);\n",
    "    hidden = lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input])).type(itype)\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]])).type(itype)\n",
    "        # 目标\n",
    "        target = Variable(torch.LongTensor([line_target[t]])).type(itype)\n",
    "        # 传入模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        # 累加损失\n",
    "        loss += criterion(output, target)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    loss = loss / len(line_input)\n",
    "    \n",
    "    # 反向传播、更新梯度\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "num_epoch = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm = LSTMNetwork(n_categories, n_letters, HIDDEN_SIZE, n_letters)\n",
    "if use_cuda:\n",
    "    lstm.cuda()\n",
    "\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：2.50，训练进度：4.98%，（0m 36s）\n",
      "第0轮，训练损失：2.44，训练进度：9.96%，（1m 8s）\n",
      "第0轮，训练损失：2.40，训练进度：14.94%，（1m 40s）\n",
      "第0轮，训练损失：2.37，训练进度：19.92%，（2m 12s）\n",
      "第0轮，训练损失：2.34，训练进度：24.91%，（2m 45s）\n",
      "第0轮，训练损失：2.32，训练进度：29.89%，（3m 17s）\n",
      "第1轮，训练损失：2.18，训练进度：38.31%，（4m 14s）\n",
      "第1轮，训练损失：2.17，训练进度：43.29%，（4m 46s）\n",
      "第1轮，训练损失：2.17，训练进度：48.28%，（5m 18s）\n",
      "第1轮，训练损失：2.16，训练进度：53.26%，（5m 50s）\n",
      "第1轮，训练损失：2.16，训练进度：58.24%，（6m 24s）\n",
      "第1轮，训练损失：2.15，训练进度：63.22%，（6m 56s）\n",
      "第2轮，训练损失：2.10，训练进度：71.65%，（7m 53s）\n",
      "第2轮，训练损失：2.09，训练进度：76.63%，（8m 25s）\n",
      "第2轮，训练损失：2.09，训练进度：81.61%，（8m 57s）\n",
      "第2轮，训练损失：2.09，训练进度：86.59%，（9m 30s）\n",
      "第2轮，训练损失：2.09，训练进度：91.57%，（10m 3s）\n",
      "第2轮，训练损失：2.08，训练进度：96.55%，（10m 35s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 2999:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            tl = train_loss.cpu() if use_cuda else train_loss\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, tl.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([tl.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf09ba67f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faeb399dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_input = make_category_input(category)\n",
    "    category_variable = Variable(torch.LongTensor([category_input])).type(itype)\n",
    "    # 第一个字符\n",
    "    char_input = make_chars_input(start_char)\n",
    "    name_variable = Variable(torch.LongTensor(char_input)).type(itype)\n",
    "   \n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = make_chars_input(char)\n",
    "            name_variable = Variable(torch.LongTensor(chars_input)).type(itype)\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran\n",
      "Untan\n",
      "Shan\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')\n",
    "# generate_one('Russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorer\n",
      "Eblan\n",
      "Rant\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarra\n",
      "Palla\n",
      "Arra\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan\n",
      "Hong\n",
      "Lu\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
