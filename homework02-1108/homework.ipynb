{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第二节：机器也懂感情？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后练习：使用 LSTM 来判断人名属于哪个国家"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们要使用 PyTorch 搭建一个 LSTM 模型。\n",
    "\n",
    "模型的输入是用ASCII字符表示的姓氏，输出是模型对这个姓氏所属语言的判断。\n",
    "\n",
    "模型的训练数据是来自18种语言的2万条左右的姓氏文本。\n",
    "\n",
    "训练完毕的理想模型可以预测出一个姓氏是属于哪种语言的。并且，我们还可以通过模型的预测结果分析各语言姓氏的相似性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终训练好的模型可以像下面那样使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "predict Hinton\n",
    "(-0.47) Scottish\n",
    "(-1.52) English\n",
    "(-3.57) Irish\n",
    "\n",
    "predict.py Schmidhuber\n",
    "(-0.19) German\n",
    "(-2.48) Czech\n",
    "(-2.68) Dutch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到本练习相信你已经对 LSTM 有一定的认识了。\n",
    "\n",
    "如果还不熟悉 LSTM 可以再去看一下张老师讲的[课程](http://campus.swarma.org/gcou=10341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在提供的数据文件中，包含在 data/names 目录下的是18个命名规则为\"[Language].txt\"的文本文件，每个文件都包含一些名字，每个名字占一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/names/Polish.txt', './data/names/Chinese.txt', './data/names/Spanish.txt', './data/names/French.txt', './data/names/Irish.txt', './data/names/Scottish.txt', './data/names/Italian.txt', './data/names/Portuguese.txt', './data/names/Korean.txt', './data/names/German.txt', './data/names/Arabic.txt', './data/names/Vietnamese.txt', './data/names/English.txt', './data/names/Czech.txt', './data/names/Japanese.txt', './data/names/Greek.txt', './data/names/Dutch.txt', './data/names/Russian.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "all_filenames = glob.glob('./data/names/*.txt')\n",
    "print(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在先让我们解决这个问题：\n",
    "\n",
    "在我们收集的18种语言的名字中，中文、日文、韩文等名字都已经转化为音译的字母。这样做是因为有些语言的名字并不能用普通的ASCII英文字符来表示，比如“Ślusàrski”，这些不一样的字母会增加神经网络的“困惑”，影响其训练效果。所以我们得首先把这些特别的字母转换成普通的ASCII字符（即26个英文字母）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n",
      "all_letters: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\n",
      "all_letters: 57\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# 使用26个英文字母大小写再加上.,;这三个字符\n",
    "# 建立字母表，并取其长度\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "# 将Unicode字符串转换为纯ASCII\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii('Ślusàrski'))\n",
    "print('all_letters:', all_letters)\n",
    "print('all_letters:', len(all_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再建立 readLines 方法，用于从文件中一行一行的将姓氏读取出来。\n",
    "\n",
    "以18种语言为索引，将读取出的姓氏各自存储在名为 `category_lines` 的字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_categories: ['Polish', 'Chinese', 'Spanish', 'French', 'Irish', 'Scottish', 'Italian', 'Portuguese', 'Korean', 'German', 'Arabic', 'Vietnamese', 'English', 'Czech', 'Japanese', 'Greek', 'Dutch', 'Russian']\n",
      "n_categories = 18\n"
     ]
    }
   ],
   "source": [
    "# 构建category_lines字典，名字和每种语言对应的列表\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# 按行读取出名字并转换成纯ASCII\n",
    "def readLines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "for filename in all_filenames:\n",
    "    # 取出每个文件的文件名（语言名）\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    # 将语言名加入到all_categories列表\n",
    "    all_categories.append(category)\n",
    "    # 取出所有的姓氏lines\n",
    "    lines = readLines(filename)\n",
    "    # 将所有姓氏以语言为索引，加入到字典中\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('all_categories:', all_categories)\n",
    "print('n_categories =', n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_categories` 中包含18中语言的姓氏。\n",
    "\n",
    "`category_lines` 中以18中语言为索引，存储了所有的姓氏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来统计下数据中所有姓氏的个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 首先导入程序所需要的程序包\n",
    "\n",
    "#PyTorch用的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "#绘图、计算用的程序包\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 尝试使用gpu加速\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们再编写一个方法用于快速地获得一个训练实例（即一个名字以及它所属的语言）：\n",
    "\n",
    "其中 line_index 中保存的是选择的姓氏中的字母的索引，这个需要你去实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = English / line = Drake\n",
      "category = 12 / line = [29, 17, 0, 10, 4]\n",
      "category = Russian / line = Dzhanakavov\n",
      "category = 17 / line = [29, 25, 7, 0, 13, 0, 10, 0, 21, 14, 21]\n",
      "category = Arabic / line = Asker\n",
      "category = 10 / line = [26, 18, 10, 4, 17]\n",
      "category = Polish / line = Sienkiewicz\n",
      "category = 0 / line = [44, 8, 4, 13, 10, 8, 4, 22, 8, 2, 25]\n",
      "category = Spanish / line = De leon\n",
      "category = 2 / line = [29, 4, 52, 11, 4, 14, 13]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():   \n",
    "    # 随机选择一种语言\n",
    "    category = random.choice(all_categories)\n",
    "    # 从语言中随机选择一个姓氏\n",
    "    line = random.choice(category_lines[category])\n",
    "    # 我们将姓氏和语言都转化为索引\n",
    "    category_index = all_categories.index(category)\n",
    "    \n",
    "    \n",
    "    line_index = [all_letters.index(w) for w in line]\n",
    "    # 你需要把 line 中字母的索引加入到line_index 中\n",
    "    # Todo:\n",
    "    \n",
    "    return category, line, category_index, line_index\n",
    "\n",
    "# 测试一下上面的函数方法\n",
    "for i in range(5):\n",
    "    category, line, category_index, line_index = random_training_pair()\n",
    "    print('category =', category, '/ line =', line)\n",
    "    print('category =', category_index, '/ line =', line_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再建立一个用户转化模型输出的辅助函数。\n",
    "\n",
    "它可以把网络的输出（1 x 18的张量）转化成“最可能的语言类别”，这就需要找到18列数据中哪个概率值最大。\n",
    "\n",
    "我们可以使用 `Tensor.topk` 方法来得到数据中最大值位置的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    # 1 代表在‘列’间找到最大\n",
    "    # top_n 是具体的值\n",
    "    # top_i 是位置索引\n",
    "    # 注意这里 top_n 和 top_i 都是1x1的张量\n",
    "    # output.data 取出张量数据\n",
    "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "    # 从张量中取出索引值\n",
    "    category_i = top_i[0][0]\n",
    "    # 返回语言类别名和位置索引\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写 LSTM 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是建立 LSTM 模型的时候了。\n",
    "\n",
    "我在模型中设置了一些空缺，**你需要编写空缺处的代码。**\n",
    "\n",
    "如果遇到问题，可以参考[课程](http://campus.swarma.org/gcou=10341)中的代码讲解哦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM的构造如下：\n",
    "        # 一个embedding层，将输入的任意一个单词（list）映射为一个向量（向量的维度与隐含层有关系？）\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 然后是一个LSTM隐含层，共有hidden_size个LSTM神经元，并且它可以根据n_layers设置层数\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        # 接着是一个全链接层，外接一个softmax输出\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        #首先根据输入input，进行词向量嵌入\n",
    "        embedded = self.embedding(input)\n",
    "        \n",
    "        # 这里需要注意！\n",
    "        # PyTorch设计的LSTM层有一个特别别扭的地方是，输入张量的第一个维度需要是时间步，\n",
    "        # 第二个维度才是batch_size，所以需要对embedded变形\n",
    "        # 因为此次没有采用batch，所以batch_size为1\n",
    "        # 变形的维度应该是（input_list_size, batch_size, hidden_size）\n",
    "        embedded = embedded.view(input.size(0), 1, self.hidden_size)\n",
    "    \n",
    "        # 调用PyTorch自带的LSTM层函数，注意有两个输入，一个是输入层的输入，另一个是隐含层自身的输入\n",
    "        # 输出output是所有步的隐含神经元的输出结果，hidden是隐含层在最后一个时间步的状态。\n",
    "        # 注意hidden是一个tuple，包含了最后时间步的隐含层神经元的输出，以及每一个隐含层神经元的cell的状态\n",
    "        \n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        #我们要把最后一个时间步的隐含神经元输出结果拿出来，送给全连接层\n",
    "        output = output[-1,...]\n",
    "\n",
    "        #全链接层\n",
    "        out = self.fc(output)\n",
    "        # softmax\n",
    "        out = self.logsoftmax(out)\n",
    "        return out\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size)).type(dtype)\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.n_layers, 1, self.hidden_size)).type(dtype)\n",
    "        return (hidden, cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次训练模型的时候，我的心里都是有点小激动的！\n",
    "\n",
    "我同样在训练程序中预留了一些空位，**你要编写空余位置的程序**，训练才可以正常进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：2.74，训练进度：2.99%，（0m 8s），名字：Meadhra，预测国家：French，正确？✗ (Irish)\n",
      "第0轮，训练损失：2.56，训练进度：5.98%，（0m 16s），名字：Kleid，预测国家：Arabic，正确？✗ (German)\n",
      "第0轮，训练损失：2.44，训练进度：8.97%，（0m 24s），名字：Ruzicka，预测国家：Polish，正确？✗ (Czech)\n",
      "第0轮，训练损失：2.35，训练进度：11.95%，（0m 32s），名字：Sotiris，预测国家：Greek，正确？✓\n",
      "第0轮，训练损失：2.26，训练进度：14.94%，（0m 40s），名字：Assen，预测国家：Irish，正确？✗ (Dutch)\n",
      "第0轮，训练损失：2.19，训练进度：17.93%，（0m 48s），名字：Bei，预测国家：Vietnamese，正确？✗ (Chinese)\n",
      "第1轮，训练损失：1.70，训练进度：22.99%，（1m 2s），名字：Cha，预测国家：Vietnamese，正确？✗ (Korean)\n",
      "第1轮，训练损失：1.70，训练进度：25.98%，（1m 10s），名字：Ahearn，预测国家：Irish，正确？✓\n",
      "第1轮，训练损失：1.68，训练进度：28.97%，（1m 18s），名字：Salomon，预测国家：Russian，正确？✗ (Polish)\n",
      "第1轮，训练损失：1.65，训练进度：31.95%，（1m 25s），名字：Sum，预测国家：Korean，正确？✗ (Chinese)\n",
      "第1轮，训练损失：1.63，训练进度：34.94%，（1m 33s），名字：Kuhn，预测国家：Korean，正确？✗ (German)\n",
      "第1轮，训练损失：1.61，训练进度：37.93%，（1m 41s），名字：Ying，预测国家：Korean，正确？✗ (Chinese)\n",
      "第2轮，训练损失：1.45，训练进度：42.99%，（1m 54s），名字：Cho，预测国家：Korean，正确？✓\n",
      "第2轮，训练损失：1.45，训练进度：45.98%，（2m 2s），名字：Jaluvka，预测国家：Polish，正确？✗ (Czech)\n",
      "第2轮，训练损失：1.44，训练进度：48.97%，（2m 10s），名字：Agnellutti，预测国家：Italian，正确？✓\n",
      "第2轮，训练损失：1.44，训练进度：51.95%，（2m 18s），名字：Akkeren，预测国家：Russian，正确？✗ (Dutch)\n",
      "第2轮，训练损失：1.43，训练进度：54.94%，（2m 26s），名字：Brose，预测国家：French，正确？✗ (German)\n",
      "第2轮，训练损失：1.42，训练进度：57.93%，（2m 34s），名字：Araujo，预测国家：Italian，正确？✗ (Portuguese)\n",
      "第3轮，训练损失：1.37，训练进度：62.99%，（2m 47s），名字：Boesch，预测国家：Scottish，正确？✗ (German)\n",
      "第3轮，训练损失：1.37，训练进度：65.98%，（2m 55s），名字：Giang，预测国家：Chinese，正确？✗ (Vietnamese)\n",
      "第3轮，训练损失：1.35，训练进度：68.97%，（3m 3s），名字：Matsoukis，预测国家：Greek，正确？✓\n",
      "第3轮，训练损失：1.34，训练进度：71.95%，（3m 10s），名字：Yu，预测国家：Korean，正确？✓\n",
      "第3轮，训练损失：1.34，训练进度：74.94%，（3m 18s），名字：Carbone，预测国家：Italian，正确？✓\n",
      "第3轮，训练损失：1.34，训练进度：77.93%，（3m 26s），名字：Wojewodzki，预测国家：Polish，正确？✓\n",
      "第4轮，训练损失：1.33，训练进度：82.99%，（3m 39s），名字：De santigo，预测国家：Italian，正确？✗ (Portuguese)\n",
      "第4轮，训练损失：1.31，训练进度：85.98%，（3m 47s），名字：Ha，预测国家：Korean，正确？✗ (Vietnamese)\n",
      "第4轮，训练损失：1.31，训练进度：88.97%，（3m 55s），名字：Sowka，预测国家：Polish，正确？✓\n",
      "第4轮，训练损失：1.30，训练进度：91.95%，（4m 2s），名字：Wright，预测国家：Scottish，正确？✓\n",
      "第4轮，训练损失：1.29，训练进度：94.94%，（4m 10s），名字：Andrysiak，预测国家：Polish，正确？✓\n",
      "第4轮，训练损失：1.28，训练进度：97.93%，（4m 18s），名字：Tivoli，预测国家：Italian，正确？✓\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# 开始训练LSTM网络\n",
    "n_epochs = 5\n",
    "\n",
    "# 构造一个LSTM网络的实例\n",
    "lstm = LSTMNetwork(n_letters, 10, n_categories, 2)\n",
    "\n",
    "if use_cuda :\n",
    "    lstm.cuda()\n",
    "\n",
    "#定义损失函数\n",
    "cost = torch.nn.NLLLoss()\n",
    "\n",
    "#定义优化器,\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.001)\n",
    "records = []\n",
    "\n",
    "# 用于计算训练时间的函数\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 开始训练，一共5个epoch，否则容易过拟合\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    #每次随机选择数据进行训练，每个 EPOCH 训练“所有名字个数”次。\n",
    "    for i in range(all_line_num):\n",
    "        \n",
    "        category, line, y, x = random_training_pair()\n",
    "        x = Variable(torch.LongTensor(x)).type(itype)\n",
    "        y = Variable(torch.LongTensor(np.array([y]))).type(itype)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step1:初始化LSTM隐含层单元的状态\n",
    "        hidden = lstm.initHidden()\n",
    "        \n",
    "        # Step2:让LSTM开始做运算，注意，不需要手工编写对时间步的循环，而是直接交给PyTorch的LSTM层。\n",
    "        # 它自动会根据数据的维度计算若干时间步\n",
    "        output = lstm(x, hidden)\n",
    "        \n",
    "        # Step3:计算损失\n",
    "        loss = cost(output, y)\n",
    "        losses.append((loss.cpu() if use_cuda else loss).data.numpy()[0])\n",
    "        \n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 2999:\n",
    "            # 判断模型的预测是否正确\n",
    "            guess, guess_i = category_from_output(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            # 计算训练进度\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * 5) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}），名字：{}，预测国家：{}，正确？{}'\\\n",
    "                .format(epoch, np.mean(losses), float(training_process), time_since(start), line, guess, correct))\n",
    "            records.append([np.mean(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd9540efda0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5IhTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd9540ef4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过姓氏分析语言的相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激动人心的时刻到了！\n",
    "\n",
    "下面将使用10000条数据评估训练好的模型，并根据评估的结果绘制图形，从图形中我们可以发现哪些语言的姓氏是相似的！\n",
    "\n",
    "**你需要自行编写 evaluate 函数的内容。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.LongTensor\u001b[0m), but expected (torch.cuda.FloatTensor source, int dim, torch.cuda.LongTensor index)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-dad2d4f77080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# 取得预测结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 取得预测结果的语言和索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-dad2d4f77080>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(line_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mline_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# 调用模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7540c65e4c30>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#首先根据输入input，进行词向量嵌入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 这里需要注意！\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.LongTensor\u001b[0m), but expected (torch.cuda.FloatTensor source, int dim, torch.cuda.LongTensor index)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 建立一个（18 x 18）的方阵张量\n",
    "# 用于保存神经网络做出的预测结果\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "# 用于评估的模型的测试次数\n",
    "n_confusion = 10000\n",
    "\n",
    "\n",
    "# 评估用方法 传进去一个名字，给出预测结果\n",
    "# 可以观察到这个方法的实现与 train 方法前半部分类似\n",
    "# 其实它就是去掉反向传播的 train 方法\n",
    "def evaluate(line_list):\n",
    "    # 调用模型前应该先初始化模型的隐含层\n",
    "    hidden = lstm.initHidden()\n",
    "    # 别忘了将输入的list转化为torch.Variable\n",
    "    line_variable = Variable(torch.LongTensor(line_list)).type(itype)\n",
    "    # 调用模型\n",
    "    output = lstm(line_variable, hidden)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 循环一万次\n",
    "for i in range(n_confusion):\n",
    "    # 随机选择测试数据，包括姓氏以及所属语言\n",
    "    category, line, category_index, line_list = random_training_pair()\n",
    "    # 取得预测结果\n",
    "    output = evaluate(line_list)\n",
    "    \n",
    "    # 取得预测结果的语言和索引\n",
    "    guess, guess_i = category_from_output(output)\n",
    "    \n",
    "    # 以姓氏实际的所属语言为行\n",
    "    # 以模型预测的所属语言为列\n",
    "    # 在方阵的特定位置增加1\n",
    "\n",
    "    confusion[category_index][guess_i] += 1\n",
    "\n",
    "# 数据归一化\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# 设置一个图表\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# 将 confusion 方阵数据传入\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# 设置图表两边的语言类别名称\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先看行再看列，行标签代表姓氏实际所属语言，列标签代表模型预测姓氏所属语言。\n",
    "\n",
    "色块颜色越亮代表预测次数越高。整张图表中对角线最亮，说明模型对大部分数据的预测都是准确的。\n",
    "\n",
    "但是！我们要观察的是预测错误的情况，即对角线以外的亮色块！\n",
    "\n",
    "先看 English 这一行，可以看到 English 对角线上的色块很暗啊，说明模型对英文姓氏的预测很差。同时，除对角线方块外，在 English 这一行可以观察到很多浅色方块，它们分别是：Czech（捷克语）、French（法语）、German（德语）、Irish（爱尔兰语）、Scottish（苏格兰语）。这些国家文化相近，姓氏相似，所以模型没能做到非常好的区分。\n",
    "\n",
    "而东方国家，让我们观察中国这一行，可以看到中国、韩国、越南（Vietnamese）的姓氏有一定的相似度，这与国家间的文化是相符的。\n",
    "\n",
    "另外还有西班牙和葡萄牙，这两个国家的姓氏也有些相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将模型封装的更易用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们重新把焦点转移到训练的模型上来。\n",
    "\n",
    "下面我要编写一个函数将训练的模型封装起来，以便于调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Dovesky\n",
      "(-0.34) Russian\n",
      "(-2.03) Polish\n",
      "(-2.62) Czech\n",
      "\n",
      "> Jackson\n",
      "(-0.78) Scottish\n",
      "(-1.86) English\n",
      "(-1.86) French\n",
      "\n",
      "> Satoshi\n",
      "(-0.17) Japanese\n",
      "(-2.19) Arabic\n",
      "(-4.35) Russian\n",
      "\n",
      "> Han\n",
      "(-0.85) Korean\n",
      "(-1.04) Chinese\n",
      "(-1.55) Vietnamese\n"
     ]
    }
   ],
   "source": [
    "# predict函数\n",
    "# 第一个参数为要进行预测的姓氏\n",
    "# 第二个参数为预测最大可能所属语言的数量\n",
    "def predict(input_line, n_predictions=3):\n",
    "    # 首先将用户输入的名字打印出来\n",
    "    print('\\n> %s' % input_line)\n",
    "    # 将用户输入的字符串转化为索引列表\n",
    "    input_line = list(map(lambda x: all_letters.find(x), input_line))\n",
    "    # 将用户输入的名字传入模型中进行预测\n",
    "    output = evaluate(input_line)\n",
    "\n",
    "    # 获得概率最大的n_predictions个语言类别\n",
    "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    # topv中保存着概率值\n",
    "    # topi中保存着位置索引\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i]\n",
    "        category_index = topi[0][i]\n",
    "        # 将预测概率最大的三种语言类别格式化后打印出来\n",
    "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "        # 将它们存储到 predictions 中\n",
    "        predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')\n",
    "predict('Han')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里本次练习就结束了，希望本次练习可以加深你对 LSTM 的认识。如果在练习中遇到了问题，可以在 火炬上的深度学习 课程讨论群 中进行提问，对不模型有不明白的地方，可以再重复学习下课程视频中的讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
