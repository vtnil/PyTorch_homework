{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第四节：彩云小译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：实现一个「英翻中」的翻译模型，并评估效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现后的模型希望能够达到这种效果：\n",
    "\n",
    "```\n",
    "> en2cn(\"Unbalanced development is one of china s successful experiences over the past years.\")\n",
    "不平衡 发展 是 我国 最近 20 年 的 成功 经验 之一 .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设计与目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 实现注意力模型；\n",
    "* 使用SRU的神经元；\n",
    "* 实现Beam Search算法来计算输出结果；\n",
    "* 实现「中翻英」，评估多次翻译后结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as DataSet\n",
    "\n",
    "# SRU包\n",
    "# 参照：https://github.com/taolei87/sru\n",
    "from sru import SRU, SRUCell\n",
    "\n",
    "# 绘图所用的包\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 尝试使用GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "\n",
    "# 即时绘图\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里希望能够通过一定的封装来在不同的数据集上训练模型。因此希望能够做到在选用「对照数据集」和给定「句子长度限制」后得到可供模型使用的训练集、校验集、测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import jieba\n",
    "import random\n",
    "\n",
    "class Lang:\n",
    "    SOS = 0\n",
    "    EOS = 1\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.wordNumb = 2\n",
    "        # 这里没有使用list结构，因为SOS与EOS为非可见的控制字符，防止与文本中的SOS或者EOS混淆\n",
    "        self.idx2word = {Lang.SOS:'SOS', Lang.EOS:'EOS'}\n",
    "        self.word2idx = {}\n",
    "        self.wordFreq = {}\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        if word in self.word2idx:\n",
    "            self.wordFreq[word] += 1\n",
    "        else:\n",
    "            self.idx2word[self.wordNumb]=word\n",
    "            self.word2idx[word]=self.wordNumb\n",
    "            self.wordFreq[word]=1\n",
    "            self.wordNumb += 1\n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def word2index(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.addWord(word)\n",
    "        return self.word2idx[word];\n",
    "    \n",
    "    def sen2indexes(self, sentence):\n",
    "        return [self.word2index(w) for w in sentence.split(' ')]\n",
    "    \n",
    "    def index2word(self, index):\n",
    "        return self.idx2word[index] if index > 0 and index < self.wordNumb else ''\n",
    "    \n",
    "    def indexes2sen(self, indexes):\n",
    "        return ' '.join([self.index2word(i) for i in indexes if i != Lang.EOS])\n",
    "    \n",
    "    def wordNum(self):\n",
    "        return self.wordNumb\n",
    "        \n",
    "\n",
    "\n",
    "class LangData:\n",
    "    \n",
    "    def __init__(self, chinese_file, english_file, encoding='utf-8', cut_chinese=False):\n",
    "        chinese = open(chinese_file,'r',encoding=encoding).read().strip().split('\\n')\n",
    "        if cut_chinese:\n",
    "            self.chinese = [self.cutChinese(s) for s in chinese]\n",
    "        else:\n",
    "            self.chinese = chinese\n",
    "        \n",
    "        english = open(english_file,'r',encoding=encoding).read().strip().split('\\n')\n",
    "        self.english = [self.normalizeEnglish(s) for s in english]\n",
    "\n",
    "           \n",
    "    # Turn a Unicode string to plain ASCII, thanks to\n",
    "    # http://stackoverflow.com/a/518232/2809427\n",
    "    # 将unicode编码转变为ascii编码\n",
    "    def u2a(self, s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "    \n",
    "    def normalizeEnglish(self, s):\n",
    "        s = self.u2a(s)\n",
    "        s = re.sub(r\"(\\W)\", r\" \\1\",s)\n",
    "        s = re.sub(r\"[^a-zA-Z0-9_,\\.\\!\\?]+\", r\" \", s)\n",
    "        s = s.lower().strip()\n",
    "        return s\n",
    "    \n",
    "    def cutChinese(self, s):\n",
    "        return \" \".join(jieba.cut(s))\n",
    "    \n",
    "    def _toIndex(self, l, s, n):\n",
    "        idx = l.sen2indexes(s)\n",
    "        for i in range(n - len(idx)):\n",
    "            idx.append(Lang.EOS)\n",
    "        return idx\n",
    "    \n",
    "    def getDataLoader(self, sen_length, batch_size, target='cn'):\n",
    "        # 构造语言对，并打乱\n",
    "        pairs = [p \n",
    "                 for p in zip(self.chinese, self.english) \n",
    "                 if (len(p[0].split(' ')) < sen_length and len(p[1].split(' ')) < sen_length)]\n",
    "        \n",
    "        random.shuffle(pairs)\n",
    "                \n",
    "        # 建立词索引\n",
    "        Chinese, English = Lang('Chinese'), Lang('English')\n",
    "        for c,e in pairs:\n",
    "            Chinese.addSentence(c)\n",
    "            English.addSentence(e)\n",
    "\n",
    "        # 文本变为索引，并且扩展为等长长度\n",
    "        pairs = [(self._toIndex(Chinese,p[0],sen_length), self._toIndex(English,p[1],sen_length)) for p in pairs]\n",
    "\n",
    "        xi,yi = (1,0) if target=='cn' else (0,1)\n",
    "        \n",
    "        # 形成训练集、校验集和测试集\n",
    "        valid_size = len(pairs) // 10\n",
    "        if valid_size > 10000:\n",
    "            valid_size = 10000\n",
    "            \n",
    "        train = torch.LongTensor(pairs[ : -valid_size])\n",
    "        valid = torch.LongTensor(pairs[-valid_size : -valid_size // 2])\n",
    "        test  = torch.LongTensor(pairs[-valid_size // 2 :])\n",
    "        \n",
    "        # 形成训练集\n",
    "        trainSet = DataSet.TensorDataset(train[:,xi], train[:,yi])\n",
    "        trainLoader = DataSet.DataLoader(trainSet, batch_size = batch_size, shuffle=True, num_workers=8)\n",
    "        # 校验数据\n",
    "        validSet = DataSet.TensorDataset(valid[:,xi], valid[:,yi])\n",
    "        validLoader = DataSet.DataLoader(validSet, batch_size = batch_size, shuffle=True, num_workers=8)\n",
    "        # 测试数据\n",
    "        testSet = DataSet.TensorDataset(test[:,xi], test[:,yi])\n",
    "        testLoader = DataSet.DataLoader(testSet, batch_size = batch_size, shuffle=True, num_workers=8)\n",
    "        \n",
    "        print('有效句子对：{}\\n训练记录：{}\\n校验记录：{}\\n测试记录：{}'\n",
    "              .format(len(pairs),len(trainSet),len(validSet),len(testSet)))\n",
    "        \n",
    "        return trainLoader, validLoader, testLoader, Chinese, English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里得到得到训练集、验证集、测试集以及语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文句子总数：100000\n",
      "英文句子总数：100000\n"
     ]
    }
   ],
   "source": [
    "langData=LangData('data/chinese.txt','data/english.txt')\n",
    "\n",
    "print('中文句子总数：{}\\n英文句子总数：{}'.format(len(langData.chinese),len(langData.english)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对：9621\n",
      "训练记录：8659\n",
      "校验记录：481\n",
      "测试记录：481\n",
      "总单词数：\n",
      "  CH: 11225\n",
      "  EN: 9185\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 16\n",
    "train, valid, test, Chi, Eng = langData.getDataLoader(MAX_LENGTH, batch_size = 30, target='cn')\n",
    "\n",
    "print(\"总单词数：\\n  CH: {}\\n  EN: {}\".format(Chi.wordNum(),Eng.wordNum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建基于AM模型的神经网络，编码器与解码器都使用SRU作为激活单元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, core='sru'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.is_sru = core == 'sru'\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        if self.is_sru:\n",
    "            self.rnn = SRU(hidden_size, hidden_size,\n",
    "                num_layers = n_layers,          # number of stacking RNN layers\n",
    "                dropout = 0.0,           # dropout applied between RNN layers\n",
    "                rnn_dropout = 0.0,       # variational dropout applied on linear transformation\n",
    "                use_tanh = 0,         # use tanh?\n",
    "                use_relu = 0,            # use ReLU?\n",
    "                bidirectional = True    # bidirectional RNN ?\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers = n_layers, bidirectional = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input尺寸： batch_size, length_seq\n",
    "        # embedded尺寸：batch_size, length_seq, hidden_size\n",
    "        embedded = self.embedding(input)\n",
    "        \n",
    "        # embedded转成：seq_size, batch_size, hidden_size\n",
    "        input = embedded.transpose(0,1).contiguous()\n",
    "        \n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "\n",
    "        # output转为：batch_size, length_seq, hidden_size\n",
    "        output = output.transpose(0,1).contiguous()\n",
    "        \n",
    "        # hidden：num_layers, batch_size, hidden_size * directions\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        if self.is_sru:\n",
    "            return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size * 2).type(dtype))\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size).type(dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attn_size, n_layers=1, dropout_p=0.1, core='sru'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.is_sru = core == 'sru'\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        # 注意力网络（一个前馈神经网络）\n",
    "        self.attn = nn.Linear(hidden_size * (2 * n_layers + 1), attn_size)\n",
    "    \n",
    "        # 注意力机制作用完后的结果映射到后面的层\n",
    "        self.attn_combine = nn.Linear(hidden_size * 3, hidden_size)\n",
    "        \n",
    "        # dropout操作层\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        if self.is_sru:\n",
    "            self.rnn = SRU(hidden_size, hidden_size,\n",
    "                num_layers = n_layers,          # number of stacking RNN layers\n",
    "                dropout = dropout_p,           # dropout applied between RNN layers\n",
    "                rnn_dropout = dropout_p,       # variational dropout applied on linear transformation\n",
    "                use_tanh = 0,         # use tanh?\n",
    "                use_relu = 0,            # use ReLU?\n",
    "                bidirectional = True    # bidirectional RNN ?\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers = n_layers, bidirectional = True)\n",
    "            \n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input大小：batch_size, length_seq=1\n",
    "        # hidden大小：n_layer, batch_size, hidden_size*direction\n",
    "        \n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded大小：batch_size, hidden_size\n",
    "        embedded = embedded[:, 0, :]\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 将hidden张量数据转化成batch_size排在第0维的形状\n",
    "        attn_input_hidden = hidden.transpose(0, 1).contiguous()\n",
    "        # hidden_attn大小：batch_size, direction*n_layers*hidden_size\n",
    "        attn_input_hidden = attn_input_hidden.view(attn_input_hidden.size(0), -1)\n",
    "        \n",
    "        # attn_input：batch_size, hidden_size * (1 + direction * n_layers)\n",
    "        attn_input = torch.cat((embedded, attn_input_hidden), 1)\n",
    "        \n",
    "        # 注意力层输出的权重\n",
    "        # attn_weights大小：batch_size, max_length\n",
    "        attn_weights = F.softmax(self.attn(attn_input))\n",
    "        \n",
    "        # 当输入数据不标准的时候，对weights截取必要的一段\n",
    "        # attn_weights大小：batch_size, length_seq_of_encoder\n",
    "        attn_weights = attn_weights[:, : encoder_outputs.size(1)]\n",
    "        # attn_weights大小：batch_size, 1, length_seq 中间的1是为了bmm乘法用的\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        \n",
    "        # 将attention的weights矩阵乘encoder_outputs以计算注意力完的结果\n",
    "        # encoder_outputs大小：batch_size, seq_length, hidden_size * 2\n",
    "        # attn_applied大小：batch_size, 1, hidden_size * 2\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs) \n",
    "        \n",
    "        # 将输入的词向量与注意力机制作用后的结果拼接成一个大的输入向量\n",
    "        # output大小：batch_size, hidden_size * (direction + 1)\n",
    "        to_combine = torch.cat((embedded, attn_applied[:,0,:]), 1)\n",
    "        \n",
    "        # 将大输入向量映射为GRU的输入向量\n",
    "        # input：batch_size, 1, hidden_size\n",
    "        input = self.attn_combine(to_combine).unsqueeze(1)\n",
    "        \n",
    "        input = F.relu(input)\n",
    "        input = self.dropout(input)\n",
    "\n",
    "        # 开始解码器SRU的运算\n",
    "        # output大小：length_seq, batch_size, hidden_size * directions\n",
    "        # hidden大小：n_layers, batch_size, hidden_size * directions\n",
    "        input = input.transpose(0, 1).contiguous()\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        \n",
    "        # output大小：batch_size * output_size\n",
    "        output = self.fc(output[-1, :, :])\n",
    "        \n",
    "        output = F.log_softmax(output)\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    \n",
    "    def initInput(self, batch_size):\n",
    "        return Variable(torch.LongTensor([[Lang.SOS]] * batch_size).type(itype))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def rightness(output, labels):\n",
    "    # predictions: batch, max_length, class_num\n",
    "#     y = torch.max(predictions.data, 1)[1]\n",
    "    rights = output.eq(labels.data).sum()\n",
    "    return rights, labels.numel()\n",
    "\n",
    "def beam_search(bn, decoder, input, hidden, encoder_outputs, max_length=MAX_LENGTH, debug=True):\n",
    "    batch_num = input.size(0)\n",
    "\n",
    "    # 执行第一步beam_search\n",
    "    decoder_output, hidden, attn = decoder(input, hidden, encoder_outputs)\n",
    "    topv, topi = decoder_output.data.topk(bn, 1)\n",
    "    \n",
    "    # 权重w存储每个baam的权重和：batch, bn\n",
    "    w = topv\n",
    "    # output: batch, bn, max_length\n",
    "    outputs = (topi.cpu() if use_cuda else topi).unsqueeze(2)\n",
    "     \n",
    "    # hiddens: bn, ...\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "    hiddens = hidden.clone()\n",
    "    for i in range(1, bn):\n",
    "        hiddens = torch.cat((hiddens, hidden.clone()), 0)\n",
    "    \n",
    "    # attns: batch, bn, max_length, max_length\n",
    "    attn = attn.unsqueeze(1).data\n",
    "    attns = attn.clone()\n",
    "    for i in range(1, bn):\n",
    "        attns = torch.cat((attns, attn.clone()), 1)\n",
    "        \n",
    "    if debug:\n",
    "        print('---0---')\n",
    "        print(\"\\n\".join([\"({:.4f}) {:s}\".format(w[0,i], Chi.indexes2sen(outputs[0,i,:].numpy())) for i in range(bn)]))\n",
    "    \n",
    "    # 循环执行后续步骤\n",
    "    for si in range(1, max_length):\n",
    "        # b_w: batch, bn*class_num\n",
    "        b_w=torch.FloatTensor().type(dtype)\n",
    "        b_a=torch.FloatTensor().type(dtype)\n",
    "        \n",
    "        for bi in range(bn):\n",
    "            input = Variable(outputs[:,bi,-1].unsqueeze(1)).type(itype)\n",
    "            decoder_output, hiddens[bi], attn = decoder(input, hiddens[bi,...], encoder_outputs)\n",
    "#             print(w[:,bi].size(), decoder_output.data.size())\n",
    "            b_w = torch.cat((b_w, (w[:,bi].unsqueeze(1) + decoder_output.data)), 1)\n",
    "            b_a = torch.cat((b_a, attn.unsqueeze(1).data), 1)\n",
    "        \n",
    "        n = decoder_output.size(1)\n",
    "        topv, topi = b_w.topk(bn, 1)\n",
    "        w = topv\n",
    "        \n",
    "        # 拼接结果\n",
    "        _o = outputs.numpy().tolist()\n",
    "        outputs = []\n",
    "        for i in range(batch_num):\n",
    "            _bn = []\n",
    "            for j in range(bn):\n",
    "                t = _o[i][topi[i, j] // n][:] if si!=0 else []\n",
    "                t.append(topi[i, j] % n)\n",
    "                _bn.append(t)\n",
    "            outputs.append(_bn)\n",
    "        outputs = torch.LongTensor(outputs)\n",
    "        attns = torch.cat((attns, b_a), 2)\n",
    "        \n",
    "        if debug:\n",
    "            print('---{}---'.format(si))\n",
    "            print(\"\\n\".join([\"({:.4f}) {:s}\".format(w[0,i], Chi.indexes2sen(outputs[0,i,:].numpy())) for i in range(bn)]))\n",
    "\n",
    "    maxwi = w.max(1)[1]\n",
    "    outputs = outputs.numpy()\n",
    "    attns = (attns.cpu() if use_cuda else attns).numpy()\n",
    "    output = [outputs[i][maxwi[i]] for i in range(batch_num)]\n",
    "    attn = [attns[i][maxwi[i]] for i in range(batch_num)]\n",
    "    \n",
    "    return output, attn, outputs, attns, w\n",
    "\n",
    "def evaluate(sentence, encoder, decoder, bn=3,  max_length=MAX_LENGTH , beam=True, debug=False):\n",
    "    if sentence.dim() == 1:\n",
    "        sentence = sentence.unsqueeze(0)\n",
    "    batch_size = sentence.size(0)\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "        \n",
    "    input = Variable(sentence)\n",
    "#     input = sentence\n",
    "    hidden = encoder.initHidden(batch_size)\n",
    "    \n",
    "    encoder_outputs, hidden = encoder(input, hidden)\n",
    "    \n",
    "    input = decoder.initInput(batch_size)\n",
    "    \n",
    "    # 使用beam_search算法\n",
    "    if beam:\n",
    "        return beam_search(bn, decoder, input, hidden, encoder_outputs, debug=debug)\n",
    "\n",
    "    # 使用最大概率生成\n",
    "    output = torch.LongTensor().type(itype)\n",
    "    attns = torch.FloatTensor().type(dtype)\n",
    "    for i in range(max_length):\n",
    "        decoder_output, hidden, attn = decoder(input, hidden, encoder_outputs)\n",
    "        output= torch.cat((output, decoder_output.data.topk(1,1)[1]), 1)\n",
    "        attns = torch.cat((attns, attn.data), 0)\n",
    "        input = Variable(output[:,-1]).unsqueeze(1)\n",
    "        \n",
    "    output = (output.cpu() if use_cuda else output).numpy()\n",
    "    attns = (attns.cpu() if use_cuda else attns).numpy()\n",
    "    return output, attns, [],[],[]\n",
    "    \n",
    "    \n",
    "        \n",
    "def training(encoder, decoder, train_loader, valid_loader, log=[], n_epoch=100, lr=0.001, max_length=MAX_LENGTH):\n",
    "    \n",
    "    teacher_forcing_ratio = 0.5\n",
    "    \n",
    "    # 为两个网络分别定义优化器\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "    # 定义损失函数\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        train_loss = 0\n",
    "        # 对训练数据循环\n",
    "        for data in train_loader:\n",
    "            input_variable = Variable(data[0]).type(itype)\n",
    "            # input_variable的大小：batch_size, length_seq\n",
    "            target_variable = Variable(data[1]).type(itype)\n",
    "            # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "            # 初始化编码器状态\n",
    "            encoder_hidden = encoder.initHidden(data[0].size(0))\n",
    "            # 清空梯度\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "            # 开始解码器的工作\n",
    "            decoder_input = decoder.initInput(target_variable.size(0))\n",
    "\n",
    "            # 传递隐藏层状态\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            # 以teacher_forcing_ratio的比例用target中的翻译结果作为监督信息\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                for di in range(MAX_LENGTH):            \n",
    "                    decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    loss += criterion(decoder_output, target_variable[:, di])\n",
    "                    decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "\n",
    "            else:\n",
    "                for di in range(MAX_LENGTH):\n",
    "                    decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    loss += criterion(decoder_output, target_variable[:, di])\n",
    "                    topv, topi = decoder_output.data.topk(1, 1)\n",
    "                    decoder_input = Variable(topi).type(itype)\n",
    "\n",
    "            # 开始反向传播\n",
    "            loss.backward()\n",
    "\n",
    "            # 开始梯度下降\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            # 累加总误差\n",
    "            train_loss += (loss.cpu() if use_cuda else loss).data.numpy()[0]\n",
    "\n",
    "        # 计算训练时候的平均误差\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "        \n",
    "        #### 开始跑校验数据集\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        valid_loss = 0\n",
    "        rights = []\n",
    "        # 对校验数据集循环\n",
    "        for data in valid_loader:\n",
    "            loss = 0\n",
    "            input_variable = Variable(data[0]).type(itype)\n",
    "            target_variable = Variable(data[1]).type(itype)\n",
    "            encoder_hidden = encoder.initHidden(data[0].size(0))\n",
    "            \n",
    "            encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "            decoder_input = decoder.initInput(target_variable.size(0))\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                \n",
    "                decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "                topv, topi = decoder_output.data.topk(1, 1)\n",
    "                decoder_input = Variable(topi).type(itype)\n",
    "\n",
    "                right = rightness(topi[:,0], target_variable[:, di])\n",
    "                rights.append(right)\n",
    "\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "            valid_loss += (loss.cpu() if use_cuda else loss).data.numpy()[0]\n",
    "            \n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "            \n",
    "        \n",
    "        # 打印每一个Epoch的输出结果\n",
    "        rights = np.array(rights)\n",
    "        right_ratio = rights[:,0].sum() / rights[:,1].sum()\n",
    "\n",
    "        print('进程：{:.1f}% 训练损失：{:.4f}，校验损失：{:.4f}，词正确率：{:.2f}% ({})'\n",
    "              .format(epoch / n_epoch * 100, train_loss, valid_loss, right_ratio * 100.0, time_since(start)))\n",
    "        log.append([train_loss, valid_loss , right_ratio])\n",
    "        \n",
    "    return log\n",
    "\n",
    "def draw_log(log):\n",
    "    a = [i[0] for i in log]\n",
    "    b = [i[1] for i in log]\n",
    "    c = [i[2] * 100 for i in log]\n",
    "    plt.plot(a, label = 'Training Loss')\n",
    "    plt.plot(b, label = 'Validation Loss')\n",
    "    plt.plot(c, label = 'Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss & Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0.0% 训练损失：72.3934，校验损失：66.8267，词正确率：42.97% (0m 17s)\n",
      "进程：2.0% 训练损失：61.7957，校验损失：65.9601，词正确率：43.43% (0m 34s)\n",
      "进程：4.0% 训练损失：51.3392，校验损失：66.8801，词正确率：41.98% (0m 51s)\n",
      "进程：6.0% 训练损失：38.9377，校验损失：69.0825，词正确率：42.89% (1m 8s)\n",
      "进程：8.0% 训练损失：33.4869，校验损失：73.3883，词正确率：40.06% (1m 25s)\n",
      "进程：10.0% 训练损失：30.3213，校验损失：71.8784，词正确率：43.35% (1m 42s)\n",
      "进程：12.0% 训练损失：27.0921，校验损失：70.5538，词正确率：40.61% (1m 59s)\n",
      "进程：14.0% 训练损失：24.2718，校验损失：75.7116，词正确率：40.10% (2m 16s)\n",
      "进程：16.0% 训练损失：22.5470，校验损失：75.7022，词正确率：42.42% (2m 33s)\n",
      "进程：18.0% 训练损失：20.9306，校验损失：72.7918，词正确率：42.23% (2m 50s)\n",
      "进程：20.0% 训练损失：19.7558，校验损失：75.3509，词正确率：40.37% (3m 7s)\n",
      "进程：22.0% 训练损失：18.7297，校验损失：79.5347，词正确率：41.24% (3m 24s)\n",
      "进程：24.0% 训练损失：17.3409，校验损失：82.2722，词正确率：41.18% (3m 41s)\n",
      "进程：26.0% 训练损失：16.7973，校验损失：79.8299，词正确率：39.90% (3m 58s)\n",
      "进程：28.0% 训练损失：16.2930，校验损失：79.3656，词正确率：41.80% (4m 15s)\n",
      "进程：30.0% 训练损失：15.6147，校验损失：81.8459，词正确率：42.58% (4m 32s)\n",
      "进程：32.0% 训练损失：14.9473，校验损失：85.6888，词正确率：41.94% (4m 49s)\n",
      "进程：34.0% 训练损失：14.4416，校验损失：81.1090，词正确率：42.16% (5m 6s)\n",
      "进程：36.0% 训练损失：14.1863，校验损失：88.3607，词正确率：42.48% (5m 23s)\n",
      "进程：38.0% 训练损失：13.8719，校验损失：87.8469，词正确率：41.35% (5m 40s)\n",
      "进程：40.0% 训练损失：13.6032，校验损失：90.5485，词正确率：42.24% (5m 57s)\n",
      "进程：42.0% 训练损失：13.0728，校验损失：88.8163，词正确率：41.88% (6m 14s)\n",
      "进程：44.0% 训练损失：12.4616，校验损失：89.1221，词正确率：41.65% (6m 32s)\n",
      "进程：46.0% 训练损失：12.5980，校验损失：90.3466，词正确率：42.29% (6m 49s)\n",
      "进程：48.0% 训练损失：12.7351，校验损失：91.3555，词正确率：40.80% (7m 6s)\n",
      "进程：50.0% 训练损失：12.2942，校验损失：92.2204，词正确率：41.89% (7m 23s)\n",
      "进程：52.0% 训练损失：11.2949，校验损失：94.0319，词正确率：42.87% (7m 40s)\n",
      "进程：54.0% 训练损失：10.8740，校验损失：91.2901，词正确率：40.96% (7m 57s)\n",
      "进程：56.0% 训练损失：10.7175，校验损失：94.2131，词正确率：41.84% (8m 14s)\n",
      "进程：58.0% 训练损失：10.4980，校验损失：95.7419，词正确率：41.61% (8m 31s)\n",
      "进程：60.0% 训练损失：10.4070，校验损失：95.5339，词正确率：42.65% (8m 48s)\n",
      "进程：62.0% 训练损失：10.2021，校验损失：99.2222，词正确率：41.07% (9m 5s)\n",
      "进程：64.0% 训练损失：10.0942，校验损失：102.5181，词正确率：42.39% (9m 22s)\n",
      "进程：66.0% 训练损失：9.4656，校验损失：99.3283，词正确率：41.72% (9m 39s)\n",
      "进程：68.0% 训练损失：9.1372，校验损失：102.8506，词正确率：42.32% (9m 56s)\n",
      "进程：70.0% 训练损失：9.4010，校验损失：98.0332，词正确率：42.10% (10m 13s)\n",
      "进程：72.0% 训练损失：9.3948，校验损失：99.4571，词正确率：41.74% (10m 30s)\n",
      "进程：74.0% 训练损失：9.1861，校验损失：102.8896，词正确率：42.32% (10m 47s)\n",
      "进程：76.0% 训练损失：9.1559，校验损失：101.7414，词正确率：42.00% (11m 4s)\n",
      "进程：78.0% 训练损失：9.0720，校验损失：100.7550，词正确率：40.76% (11m 21s)\n",
      "进程：80.0% 训练损失：9.1724，校验损失：104.2451，词正确率：42.22% (11m 38s)\n",
      "进程：82.0% 训练损失：8.6903，校验损失：103.5315，词正确率：41.76% (11m 55s)\n",
      "进程：84.0% 训练损失：8.6687，校验损失：106.6055，词正确率：41.10% (12m 12s)\n",
      "进程：86.0% 训练损失：8.4986，校验损失：105.9342，词正确率：42.26% (12m 29s)\n",
      "进程：88.0% 训练损失：8.0288，校验损失：108.8192，词正确率：42.23% (12m 46s)\n",
      "进程：90.0% 训练损失：7.9198，校验损失：113.8104，词正确率：40.75% (13m 3s)\n",
      "进程：92.0% 训练损失：8.4032，校验损失：113.4660，词正确率：42.14% (13m 20s)\n",
      "进程：94.0% 训练损失：8.3538，校验损失：116.2699，词正确率：42.36% (13m 37s)\n",
      "进程：96.0% 训练损失：7.9622，校验损失：110.9287，词正确率：42.06% (13m 54s)\n",
      "进程：98.0% 训练损失：8.3667，校验损失：113.6640，词正确率：41.96% (14m 11s)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "core = 'sru'\n",
    "\n",
    "encoder = Encoder(Eng.wordNum(), hidden_size, n_layers = n_layers, core=core)\n",
    "decoder = Decoder(hidden_size, Chi.wordNum(), n_layers = n_layers , attn_size=MAX_LENGTH, dropout_p=0.3, core=core)\n",
    "if use_cuda:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "log = []\n",
    "log = training(encoder, decoder, train, valid, log=log, max_length=MAX_LENGTH, lr=0.001, n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcI551xDniCcc8419H8KAExE9rT7tAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4c3459cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取测试集的第一个batch，输出机器翻译结果和标准答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for td in test:\n",
    "    x = td[0].type(itype)\n",
    "    y = td[1].type(itype)\n",
    "    \n",
    "    break\n",
    "output, attn, outputs, attns, w = evaluate(x, encoder, decoder, bn=1,  max_length=MAX_LENGTH, beam=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入<：general office of the npc standing committee 11 january 2001\n",
      "输出>：全国 中国\n",
      "标准=：全国 人大 常委会 办公厅 2001年1月11日\n",
      "\n",
      "输入<：this will unavoidably aggravate antagonism between countries in the region .\n",
      "输出>：这 还 今后 之下 的 的 於 地区 .\n",
      "标准=：调整 思路 迎接 挑战 --- 俄 启动 新 军事 变革 孟浪 谷亚平\n",
      "\n",
      "输入<：the two are mutually complementary , and none can be dispensed with .\n",
      "输出>：双方 两 航天 , 机遇 .\n",
      "标准=：二者 相辅相成 , 缺一不可 .\n",
      "\n",
      "输入<：how does the concept of fighting a decisive battle offshore come about ?\n",
      "输出>：怎样 更新 观念 观念 \" 保管员 \" ?\n",
      "标准=：\" 决战 境外 \" 是 如何 出笼 的 ?\n",
      "\n",
      "输入<：after repeated votes , the senate overwhelmingly rejected these amendments .\n",
      "输出>：当地 , 此 后 还 后 , 就 发表 了 .\n",
      "标准=：参议院 经过 多次 表决 , 以 压倒 多数 否决 了 有关 修正案 .\n",
      "\n",
      "输入<：parliamentary exchanges are an important component of the two countries relations .\n",
      "输出>：这 对 两国 关系 的 重要 的 的 .\n",
      "标准=：议会 交往 是 两国 关系 的 重要 组成部分 .\n",
      "\n",
      "输入<：chi haotian also recalled with deep feeling past scenes during the years of war .\n",
      "输出>：迟浩田 对华 两 迟浩田 和 他 对 有关 的 的 .\n",
      "标准=：迟浩田 还 深情 地 回忆 起 烽火 岁月 的 一 幕 幕 往事 .\n",
      "\n",
      "输入<：attempts to maintain continuous development of taiwan s economy have been of utmost urgency .\n",
      "输出>：对 七 要 对 世界 随 , 要 打 .\n",
      "标准=：设法 保持 台湾 经济 的 持续 发展 , 已经 到 了 刻不容缓 的 时候 .\n",
      "\n",
      "输入<：there are some 200 countries and 2500 nationalities in the world .\n",
      "输出>：当今 有 一些 技术性 , , 应该 许多 .\n",
      "标准=：全世界 约 有 200 国家 , 2500 民族 .\n",
      "\n",
      "输入<：neither is dispensable nor is overemphasized at the expense of the other .\n",
      "输出>：此 总统 的 的 的 的 的 自我 .\n",
      "标准=：二 者 缺一不可 , 也 不可偏废 . \"\n",
      "\n",
      "输入<：enhance understanding and unify thinking .\n",
      "输出>：代表 认识 , 了解 监督 .\n",
      "标准=：提高 认识 , 统一思想 .\n",
      "\n",
      "输入<：some regional blockades are corrupt behavior in which powers are bartered for cash .\n",
      "输出>：他 是 一些 的 地区 , , 也 有 不少 的 .\n",
      "标准=：还有 一些 地区 封锁 , 背后 是 钱 权 交易 的 腐败 行为 .\n",
      "\n",
      "输入<：according to analysis , there are the following reasons for this .\n",
      "输出>：俄罗斯 该 俄罗斯 对此 有 有 背景 .\n",
      "标准=：据 分析 , 这 有 以下 几个 原因 .\n",
      "\n",
      "输入<：the central authorities policy on tibet is correct , and it enjoys popular support .\n",
      "输出>：中央 中央 给予 , 中央 给予 给予 的 .\n",
      "标准=：中央 对 西藏 的 政策 是 正确 的 , 深入人心 .\n",
      "\n",
      "输入<：retroactive payment of arrears of pension for retired personnel has been successful .\n",
      "输出>：对 这个 力度 也 完成 .\n",
      "标准=：补发 拖欠 离退休 人员 养老金 的 工作 取得 成效 .\n",
      "\n",
      "输入<：we will absolutely not tolerate such a situation .\n",
      "输出>：我们 绝 不会 容忍 的 .\n",
      "标准=：是 我们 决不能 容许 的 .\n",
      "\n",
      "输入<：the world s noble cause of peace and development is still facing stern challenges .\n",
      "输出>：世界 在 的 的 思想 的 的 的 目标 .\n",
      "标准=：世界 和平 与 发展 的 崇高 事业 依然 面临 严峻 挑战 .\n",
      "\n",
      "输入<：is this democracy ? it is a typical logic of hegemony .\n",
      "输出>：这 是 我们 是 有 的 的 的 的 .\n",
      "标准=：这 哪里 是 什 幺 民主 , 这是 典型 的 霸权 逻辑 .\n",
      "\n",
      "输入<：yet , there is also a political motive behind this economic aid .\n",
      "输出>：其 , 就 就 这 这 会 选举 的 .\n",
      "标准=：何况 , 经济账 里 还 藏 着 \" 政治 牌 \" .\n",
      "\n",
      "输入<：we demand that japan be true in word and resolute in deed .\n",
      "输出>：一定 说明 总 在 对抗 日本 要求 .\n",
      "标准=：我们 要求 日方 言必信 , 行必果 .\n",
      "\n",
      "输入<：both sides can exchange views on international and regional issues of their common concern .\n",
      "输出>：双方 就 双方 就 解决 国际 国际 和 地区 问题 的 问题 .\n",
      "标准=：亚 欧 双方 可 就 共同 感兴趣 的 国际 和 地区 问题 交换 意见 .\n",
      "\n",
      "输入<：the world needs multi polarization .\n",
      "输出>：世界 世界 不 不 人才 的 .\n",
      "标准=：世界 需要 多极化 .\n",
      "\n",
      "输入<：it is necessary to distinguish between essentials and nonessentials .\n",
      "输出>：对 , 要 不可能 的 的 .\n",
      "标准=：分清 主流 和 支流 .\n",
      "\n",
      "输入<：strengthening agriculture is related to the overall situation of economic development and social stability .\n",
      "输出>：这 是 这些 社会 局势 的 社会 社会 的 社会 .\n",
      "标准=：加强 农业 , 事关 经济 发展 和 社会 稳定 的 全局 .\n",
      "\n",
      "输入<：the credit system is the primary cornerstone of the modern market economy .\n",
      "输出>：当前 体系 体系 是 从 产业 项目 .\n",
      "标准=：信用 制度 是 现代 市场经济 的 第一 基石 .\n",
      "\n",
      "输入<：bangladesh also received a visiting us president for the first time .\n",
      "输出>：我 还 说 , 这 第一 发生 了 .\n",
      "标准=：孟加拉国 也是 建国 以来 第一 接待 美国 总统 的 访问 .\n",
      "\n",
      "输入<：deng xiaoping said that to lead is to serve .\n",
      "输出>：说 说 , 他 说 , 他 的 好 .\n",
      "标准=：各级 干部 肩负 著 领导 的 责任 .\n",
      "\n",
      "输入<：deepening the all round ties of mutually beneficial cooperation .\n",
      "输出>：现实 , 应当 了 喜人 .\n",
      "标准=：二 , 深化 全方位 的 互利 合作 关系 .\n",
      "\n",
      "输入<：the taiwan authorities are playing a dangerous game .\n",
      "输出>：当局 当局 领导人 已经 了 一 诚意 .\n",
      "标准=：台湾 当局 在 玩 一种 危险 的 游戏 .\n",
      "\n",
      "输入<：policemen on duty immediately discovered this and put out the fire .\n",
      "输出>：其中 搞活 在 北京 , 优化 的 .\n",
      "标准=：我 执勤 民警 及时 发现 并 扑救 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "# print(output[i])\n",
    "# print(\"\\n\".join([\"{:d}.[{:.4f}] > {:s}\".format(j, w[i][j], Chi.indexes2sen(outputs[i][j])) for j in range(3)]))\n",
    "for i in range(30):\n",
    "    print(\"输入<：{}\\n输出>：{}\\n标准=：{}\\n\".format(\n",
    "        Eng.indexes2sen(x[i].cpu().numpy()),\n",
    "        Chi.indexes2sen(output[i]), \n",
    "        Chi.indexes2sen(y[i,:].cpu().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def en2cn(sentence, bn=1, debug=False):\n",
    "    x = torch.LongTensor(langData._toIndex(Eng,sentence,MAX_LENGTH)).type(itype)\n",
    "    output, attn, outputs, attns, w = evaluate(x, encoder, decoder, bn=bn,  max_length=MAX_LENGTH, debug=debug) \n",
    "    print(\"\\n\".join([\"> [{:.4f}] {:s}\".format(w[0][j], Chi.indexes2sen(outputs[0][j])) for j in range(bn)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用测试，当 bn 设置为 1 的时候，beam_search 退化为经典最大值算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [-5.3089] 代表 认识 , 了解 监督 .\n"
     ]
    }
   ],
   "source": [
    "en2cn('enhance understanding and unify thinking .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试输出概率最大的三个翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [-5.1817] 代表 认识 了解 , 意识 .\n",
      "> [-5.2232] 代表 深刻 , 了解 监督 .\n",
      "> [-5.6519] 代表 认识 , 了解 , 意识 .\n"
     ]
    }
   ],
   "source": [
    "en2cn('enhance understanding and unify thinking .', bn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 Beam_search 一步步是如何工作的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---0---\n",
      "(-0.6119) 代表\n",
      "(-1.5805) 三\n",
      "(-1.6381) 加强\n",
      "---1---\n",
      "(-1.6041) 代表 认识\n",
      "(-1.8916) 代表 深刻\n",
      "(-2.0122) 代表 加强\n",
      "---2---\n",
      "(-2.5654) 代表 深刻 ,\n",
      "(-2.7179) 代表 认识 ,\n",
      "(-3.0411) 代表 认识 了解\n",
      "---3---\n",
      "(-3.6788) 代表 认识 了解 ,\n",
      "(-3.6985) 代表 深刻 , 了解\n",
      "(-3.7443) 代表 认识 , 了解\n",
      "---4---\n",
      "(-4.0302) 代表 认识 , 了解 ,\n",
      "(-4.5215) 代表 深刻 , 了解 监督\n",
      "(-4.8960) 代表 认识 了解 , 意识\n",
      "---5---\n",
      "(-5.0025) 代表 深刻 , 了解 监督 .\n",
      "(-5.1008) 代表 认识 了解 , 意识 .\n",
      "(-5.4924) 代表 认识 , 了解 , 意识\n",
      "---6---\n",
      "(-5.1602) 代表 认识 了解 , 意识 .\n",
      "(-5.2148) 代表 深刻 , 了解 监督 .\n",
      "(-5.6374) 代表 认识 , 了解 , 意识 .\n",
      "---7---\n",
      "(-5.1793) 代表 认识 了解 , 意识 .\n",
      "(-5.2222) 代表 深刻 , 了解 监督 .\n",
      "(-5.6506) 代表 认识 , 了解 , 意识 .\n",
      "---8---\n",
      "(-5.1813) 代表 认识 了解 , 意识 .\n",
      "(-5.2231) 代表 深刻 , 了解 监督 .\n",
      "(-5.6517) 代表 认识 , 了解 , 意识 .\n",
      "---9---\n",
      "(-5.1816) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---10---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---11---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---12---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---13---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---14---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "---15---\n",
      "(-5.1817) 代表 认识 了解 , 意识 .\n",
      "(-5.2232) 代表 深刻 , 了解 监督 .\n",
      "(-5.6519) 代表 认识 , 了解 , 意识 .\n",
      "> [-5.1817] 代表 认识 了解 , 意识 .\n",
      "> [-5.2232] 代表 深刻 , 了解 监督 .\n",
      "> [-5.6519] 代表 认识 , 了解 , 意识 .\n"
     ]
    }
   ],
   "source": [
    "en2cn('enhance understanding and unify thinking .', bn=3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存网络结构和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(encoder, 'encoder-toy.pkl')\n",
    "torch.save(decoder, 'decoder-toy.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结本作业有几个收获：\n",
    "\n",
    "* 通过重新组织代码，梳理清晰了各部分的逻辑，同时增加了对 pytorch 的熟悉程度；\n",
    "* 通过使用 SRU，了解了 SRU 与 GRU 的对比情况；\n",
    "* 通过实现 Beam search 算法，增加了对各种数据类型操作的熟悉程度；\n",
    "* 中间还遇到一个小插曲，通过对问题的排查，增加了调试训练的能力；\n",
    "* 通过多参数跑数据集，了解到在这个实验中，注意力网络在中英翻译上的局限；\n",
    "* 基本实现了作业最初定的目标，「中翻英」以及进一步的实验因为翻译效果不理想，所以索性不再继续；\n",
    "* 16 词长度，使用本代码大概占用 1G 左右显存；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Debug\n",
    "\n",
    "尝试通过替换模块来调试程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 第一层Embeddeing\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 第二层GRU，注意GRU中可以定义很多层，主要靠num_layers控制\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True, \n",
    "                          num_layers = self.n_layers, bidirectional = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #前馈过程\n",
    "        #input尺寸： batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded尺寸：batch_size, length_seq, hidden_size\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output尺寸：batch_size, length_seq, hidden_size\n",
    "        # hidden尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含单元变量全部进行初始化\n",
    "        #num_layers * num_directions, batch, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "# 定义基于注意力的解码器RNN\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        # 注意力网络（一个前馈神经网络）\n",
    "        self.attn = nn.Linear(self.hidden_size * (2 * n_layers + 1), self.max_length)\n",
    "    \n",
    "        # 注意力机制作用完后的结果映射到后面的层\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        \n",
    "        # dropout操作层\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 定义一个双向GRU，并设置batch_first为True以方便操作\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, bidirectional = True,\n",
    "                         num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # 解码器的一步操作\n",
    "        # input大小：batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        embedded = embedded[:, 0, :]\n",
    "        # embedded大小：batch_size, hidden_size\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 将hidden张量数据转化成batch_size排在第0维的形状\n",
    "        # hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "        temp_for_transpose = torch.transpose(hidden, 0, 1).contiguous()\n",
    "        temp_for_transpose = temp_for_transpose.view(temp_for_transpose.size()[0], -1)\n",
    "        hidden_attn = temp_for_transpose\n",
    "        \n",
    "        # 注意力层的输入\n",
    "        # hidden_attn大小：batch_size, direction*n_layers*hidden_size\n",
    "        input_to_attention = torch.cat((embedded, hidden_attn), 1)\n",
    "        # input_to_attention大小：batch_size, hidden_size * (1 + direction * n_layers)\n",
    "        \n",
    "        # 注意力层输出的权重\n",
    "        attn_weights = F.softmax(self.attn(input_to_attention))\n",
    "        # attn_weights大小：batch_size, max_length\n",
    "        \n",
    "        # 当输入数据不标准的时候，对weights截取必要的一段\n",
    "        attn_weights = attn_weights[:, : encoder_outputs.size()[1]]\n",
    "        # attn_weights大小：batch_size, length_seq_of_encoder\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        # attn_weights大小：batch_size, 1, length_seq 中间的1是为了bmm乘法用的\n",
    "        \n",
    "        # 将attention的weights矩阵乘encoder_outputs以计算注意力完的结果\n",
    "        # encoder_outputs大小：batch_size, seq_length, hidden_size*direction\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs) \n",
    "        # attn_applied大小：batch_size, 1, hidden_size*direction\n",
    "        # bmm: 两个矩阵相乘。忽略第一个batch纬度，缩并时间维度\n",
    "        \n",
    "        # 将输入的词向量与注意力机制作用后的结果拼接成一个大的输入向量\n",
    "        output = torch.cat((embedded, attn_applied[:,0,:]), 1)\n",
    "        # output大小：batch_size, hidden_size * (direction + 1)\n",
    "        \n",
    "        # 将大输入向量映射为GRU的隐含层\n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        # output大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # output的结果再dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # 开始解码器GRU的运算\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        \n",
    "        #取出GRU运算最后一步的结果喂给最后一层全链接层\n",
    "        output = self.out(output[:, -1, :])\n",
    "        # output大小：batch_size * output_size\n",
    "        \n",
    "        # 取logsoftmax，计算输出结果\n",
    "        output = F.log_softmax(output)\n",
    "        # output大小：batch_size * output_size\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 初始化解码器隐单元，尺寸为n_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    def initInput(self, batch_size):\n",
    "        return Variable(torch.LongTensor([[Lang.SOS]] * batch_size).type(itype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "n_layers = 1\n",
    "core = 'sru'\n",
    "\n",
    "encoder_t = EncoderRNN(Chi.wordNum(), hidden_size, n_layers = n_layers)\n",
    "decoder_t = AttnDecoderRNN(hidden_size, Eng.wordNum(), n_layers = n_layers , dropout_p=0.5)\n",
    "if use_cuda:\n",
    "    encoder_t.cuda()\n",
    "    decoder_t.cuda()\n",
    "\n",
    "log = []\n",
    "log = training(encoder_t, decoder_t, train, valid, log=log, max_length=MAX_LENGTH, lr=0.0001, n_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "有效句子对： 1836\n",
      "总单词数:\n",
      "Chinese 3324\n",
      "English 3011\n",
      "训练记录： 1653\n",
      "校验记录： 91\n",
      "测试记录： 92\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "# 读取平行语料库\n",
    "# 这是人民日报语料库\n",
    "lines = open('data/chinese.txt', encoding = 'utf-8')\n",
    "chinese = lines.read().strip().split('\\n')\n",
    "lines = open('data/english.txt', encoding = 'utf-8')\n",
    "english = lines.read().strip().split('\\n')\n",
    "print(len(chinese))\n",
    "print(len(english))\n",
    "\n",
    "# 定义两个特殊符号，分别对应句子头和句子尾\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "# 定义一个语言类，方便进行自动的建立、词频的统计等\n",
    "# 在这个对象中，最重要的是两个字典：word2index，index2word\n",
    "# 故名思议，第一个字典是将word映射到索引，第二个是将索引映射到word\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # 在语言中添加一个新句子，句子是用空格隔开的一组单词\n",
    "        # 将单词切分出来，并分别进行处理\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # 插入一个单词，如果单词已经在字典中，则更新字典中对应单词的频率\n",
    "        # 同时建立反向索引，可以从单词编号找到单词\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "# 将unicode编码转变为ascii编码\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 把输入的英文字符串转成小写\n",
    "def normalizeEngString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 对输入的单词对做过滤，保证每句话的单词数不能超过MAX_LENGTH\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 输入一个句子，输出一个单词对应的编码序列\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# 和上面的函数功能类似，不同在于输出的序列等长＝MAX_LENGTH\n",
    "def indexFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    for i in range(MAX_LENGTH - len(indexes)):\n",
    "        indexes.append(EOS_token)\n",
    "    return(indexes)\n",
    "\n",
    "# 从一个词对到下标\n",
    "def indexFromPair(pair):\n",
    "    input_variable = indexFromSentence(input_lang, pair[0])\n",
    "    target_variable = indexFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "# 从一个列表到句子\n",
    "def SentenceFromList(lang, lst):\n",
    "    result = [lang.index2word[i] for i in lst if i != EOS_token]\n",
    "    if lang.name == 'Chinese':\n",
    "        result = ' '.join(result)\n",
    "    else:\n",
    "        result = ' '.join(result)\n",
    "    return(result)\n",
    "\n",
    "\n",
    "# 计算准确度的函数\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 重新处理数据形成训练数据、校验数据与测试数据，主要是MAX_Length更大了\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[chi, normalizeEngString(eng)] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('Chinese')\n",
    "output_lang = Lang('English')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 30 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：58.4112，校验损失：49.4798，词正确率：31.40%\n",
      "进程：1% 训练损失：47.3585，校验损失：48.5506，词正确率：32.67%\n",
      "进程：2% 训练损失：45.3690，校验损失：48.9167，词正确率：32.56%\n",
      "进程：3% 训练损失：44.5954，校验损失：48.0342，词正确率：32.91%\n",
      "进程：4% 训练损失：43.6130，校验损失：47.8174，词正确率：32.79%\n",
      "进程：5% 训练损失：42.4692，校验损失：47.9798，词正确率：33.14%\n",
      "进程：6% 训练损失：41.4694，校验损失：47.6592，词正确率：33.26%\n",
      "进程：7% 训练损失：40.2288，校验损失：47.8592，词正确率：33.60%\n",
      "进程：8% 训练损失：39.2850，校验损失：47.9711，词正确率：34.88%\n",
      "进程：9% 训练损失：38.0226，校验损失：48.6809，词正确率：32.33%\n",
      "进程：10% 训练损失：37.0786，校验损失：48.2187，词正确率：33.84%\n",
      "进程：11% 训练损失：35.8032，校验损失：49.0991，词正确率：30.93%\n",
      "进程：12% 训练损失：34.8677，校验损失：48.8506，词正确率：32.91%\n",
      "进程：13% 训练损失：34.0522，校验损失：49.0518，词正确率：33.02%\n",
      "进程：14% 训练损失：32.7393，校验损失：49.6140，词正确率：31.28%\n",
      "进程：15% 训练损失：31.7716，校验损失：49.9875，词正确率：32.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-620:\n",
      "Process Process-619:\n",
      "Process Process-617:\n",
      "Process Process-622:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-621:\n",
      "Traceback (most recent call last):\n",
      "Process Process-623:\n",
      "Process Process-618:\n",
      "Traceback (most recent call last):\n",
      "Process Process-624:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/vtnil/anaconda3/envs/torch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a8457959413a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# 反向传播开始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# 开始梯度下降\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算准确度的函数\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素\n",
    "\n",
    "# 定义两个特殊符号，分别对应句子头和句子尾\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "#定义网络架构\n",
    "hidden_size = 512\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "core='sru'\n",
    "\n",
    "\n",
    "encoder = EncoderRNN(Chi.wordNum(), hidden_size, n_layers = n_layers)\n",
    "decoder = AttnDecoderRNN(hidden_size, Eng.wordNum(), dropout_p=0.5,\n",
    "                         max_length = max_length, n_layers = n_layers)\n",
    "\n",
    "# encoder = Encoder(input_lang.n_words, hidden_size, n_layers = n_layers, core=core)\n",
    "# decoder = Decoder(hidden_size, output_lang.n_words, n_layers = n_layers , attn_size=MAX_LENGTH, dropout_p=0.2, core=core)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = Batch_NLLLoss\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "# 开始训练周期循环\n",
    "plot_losses = []\n",
    "for epoch in range(num_epoch):\n",
    "    # 将解码器置于训练状态，让dropout工作\n",
    "    decoder.train()\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据进行循环\n",
    "    for data in train:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        #清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        #编码器开始工作\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 解码器开始工作\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 将编码器的隐含层单元取值作为编码的结果传递给解码器\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 同时按照两种方式训练解码器：用教师监督的信息作为下一时刻的输入和不用监督的信息，用自己预测结果作为下一时刻的输入\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        if use_teacher_forcing:\n",
    "            # 用监督信息作为下一时刻解码器的输入\n",
    "            # 开始时间不得循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 输入给解码器的信息包括输入的单词decoder_input, 解码器上一时刻的因曾单元状态，\n",
    "                # 编码器各个时间步的输出结果\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size\n",
    "                #计算损失函数，得到下一时刻的解码器的输入\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "        else:\n",
    "            # 没有教师监督，用解码器自己的预测作为下一时刻的输入\n",
    "\n",
    "            # 对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                # 获取解码器的预测结果，并用它来作为下一时刻的输入\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 反向传播开始\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    print_loss_avg = print_loss_total / len(train)\n",
    "        \n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 将解码器的training设置为False，以便关闭dropout\n",
    "    decoder.eval()\n",
    "    \n",
    "    #对所有的校验数据做循环\n",
    "    for data in valid:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 开始每一步的预测\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            right = rightness(decoder_output, target_variable[:, di])\n",
    "            rights.append(right)\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 计算平均损失、准确率等指标并打印输出\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid),\n",
    "                                                    100.0 * right_ratio))\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid), right_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
